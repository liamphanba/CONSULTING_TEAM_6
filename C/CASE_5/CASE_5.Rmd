---
title: "CASE_3"
author: "Liam Phan, Michael Bigler, Tania Loureiro, William Elkiess, Dakota Cuellar and Ilyana El Mendili"
date: "`r Sys.Date()`"
output: 
  rmdformats::downcute:
    code_folding: hide
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE,comment = FALSE, error = FALSE,options(scipen=999))
rm(list = ls())
```

# Packages

```{r packages}
library(DT)
library(summarytools)
library(corrplot)
library(dplyr)
library(GGally)
library(fastDummies)
library(ggcorrplot)
library(klaR)
library(psych)
library(MASS)
# library(ggord)
library(devtools)
library(ggplot2)
library(ggthemes)
library(GGally)

CM_Function <- function(cm) {

  layout(matrix(c(1,1,2)))
  par(mar=c(2,2,2,2))
  plot(c(100, 345), c(300, 450), type = "n", xlab="", ylab="", xaxt='n', yaxt='n')
  title('CONFUSION MATRIX', cex.main=2)

  # create the matrix 
  rect(150, 430, 240, 370, col='#2F4F4E')
  text(195, 435, 'No', cex=1.2)
  rect(250, 430, 340, 370, col='#0D8387')
  text(295, 435, 'Yes', cex=1.2)
  text(125, 370, 'Predicted', cex=1.3, srt=90, font=2)
  text(245, 450, 'Actual', cex=1.3, font=2)
  rect(150, 305, 240, 365, col='#0D8387')
  rect(250, 305, 340, 365, col='#2F4F4E')
  text(140, 400, 'No', cex=1.2, srt=90)
  text(140, 335, 'Yes', cex=1.2, srt=90)

  # add in the cm results 
  res <- as.numeric(cm$table)
  text(195, 400, res[1], cex=1.6, font=2, col='white')
  text(195, 335, res[2], cex=1.6, font=2, col='white')
  text(295, 400, res[3], cex=1.6, font=2, col='white')
  text(295, 335, res[4], cex=1.6, font=2, col='white')

  # add in the specifics 
  plot(c(100, 0), c(100, 0), type = "n", xlab="", ylab="", main = "DETAILS", xaxt='n', yaxt='n')
  text(10, 85, names(cm$byClass[1]), cex=1.2, font=2)
  text(10, 70, round(as.numeric(cm$byClass[1]), 3), cex=1.2)
  text(30, 85, names(cm$byClass[2]), cex=1.2, font=2)
  text(30, 70, round(as.numeric(cm$byClass[2]), 3), cex=1.2)
  text(50, 85, names(cm$byClass[5]), cex=1.2, font=2)
  text(50, 70, round(as.numeric(cm$byClass[5]), 3), cex=1.2)
  text(70, 85, names(cm$byClass[6]), cex=1.2, font=2)
  text(70, 70, round(as.numeric(cm$byClass[6]), 3), cex=1.2)
  text(90, 85, names(cm$byClass[7]), cex=1.2, font=2)
  text(90, 70, round(as.numeric(cm$byClass[7]), 3), cex=1.2)

  # add in the accuracy information 
  text(30, 35, names(cm$overall[1]), cex=1.5, font=2)
  text(30, 20, round(as.numeric(cm$overall[1]), 3), cex=1.4)
  text(70, 35, names(cm$overall[2]), cex=1.5, font=2)
  text(70, 20, round(as.numeric(cm$overall[2]), 3), cex=1.4)
}  

#options(repos = c(
    #fawda123 = 'https://fawda123.r-universe.dev',
    #CRAN = 'https://cloud.r-project.org'))

# Install ggord
#install.packages('ggord')

```

# Data and Feature Engineering

```{r data loading}

df <- readxl::read_xls('Cchurn.xls')
df$international_plan <- factor(df$international_plan, levels = c('no', 'yes'))
df$voice_mail_plan <- factor(df$voice_mail_plan, levels = c('no', 'yes'))
df$churn <- factor(df$churn, levels = c('no', 'yes'))

```

## Summary

```{r summary}
print(summarytools::dfSummary(df), method = 'render')
```

* We have no missing values -> perfect
* Heavily uneven counts of dependent variable (86 % no / 14 % yes) -> maybe sample for equality / maybe not because we loose information of other data
* Independent variables are on different scales -> standardize
* two (maybe three) categorical predictors: International plan / voice_mail_plan (/ maybe number_customer_service_calls) -> dummy encode -> not necessary as already 0 and 1
* Rest of data is numeric and most of the variables looks normally distributed with exception of number_vmail_messages and totat_intl_calls
  * transform these value to make them normal?
  * maybe make parts of them categorical? (recieving voice mail or not, calling internationally or not)
  * or maybe the categorical values that we have already give an indication for this
  * Test normality of variables
* Can variables be combined? We have day / eve / night / intl calls and for each of them minutes / calls / charge. Maybe we can combine this into one metric. Maybe average cost per minute or average cost per call? 

## Correlation Plot

```{r correlation}

df_numeric <- select_if(df, is.numeric)  # Subset numeric columns with dplyr

M <- cor(df_numeric)

p.mat <- cor_pmat(df_numeric)

ggcorrplot(M, hc.order = TRUE, type = "lower", lab = TRUE, p.mat = p.mat, sig.level=0.05, lab_size = 2, tl.cex = 10,outline.col = "white", ggtheme = ggplot2::theme_minimal(), colors = c("#823038", "white", "#2596be")) 

```

Proves theory from before -> we can make one metric out of charge and minutes --> charge / minutes

## Data Engineering

```{r transform metrics}
df$total_day_charge_per_minute <- ifelse(df$total_day_minutes == 0, 0, df$total_day_charge / df$total_day_minutes)
df$total_eve_charge_per_minute <- ifelse(df$total_eve_minutes == 0, 0, df$total_eve_charge / df$total_eve_minutes)
df$total_night_charge_per_minute <- ifelse(df$total_night_minutes == 0, 0, df$total_night_charge / df$total_night_minutes)
df$total_intl_charge_per_minute <- ifelse(df$total_intl_minutes == 0, 0, df$total_intl_charge / df$total_intl_minutes)
df <- subset(df, select = -c(total_day_charge, total_day_minutes, total_eve_charge, total_eve_minutes, total_night_charge, total_night_minutes, total_intl_charge, total_intl_minutes))
```

## Correlation Plot

```{r correlation 2}

df_numeric <- select_if(df, is.numeric)  # Subset numeric columns with dplyr

M <- cor(df_numeric)

p.mat <- cor_pmat(df_numeric)

ggcorrplot(M, hc.order = TRUE, type = "lower", lab = TRUE, p.mat = p.mat, sig.level=0.05, lab_size = 2, tl.cex = 10,outline.col = "white", ggtheme = ggplot2::theme_minimal(), colors = c("#823038", "white", "#2596be")) 

```

Now we have non-correlated data

## Sampling Methods

```{r}

library(ROSE)

# OVER
df_OVER <- ovun.sample(churn~., data = df, method = "over")$data

table(df$churn)
table(df_OVER$churn)

# UNDER
df_UNDER <- ovun.sample(churn~., data = df, method = "under")$data

table(df$churn)
table(df_UNDER$churn)

# BOTH
df_BOTH <- ovun.sample(churn~., data = df, method = "both")$data

table(df$churn)
table(df_BOTH$churn)

# ROSE
df_ROSE <- ROSE(churn ~ ., data = df, seed = 1)$data


```

## Sampling Visualization

```{r}

theme_set(theme_minimal())

ggpairs(
  data = df,
  columns = c(1:9,11:14),
  mapping = aes(col = churn, alpha = .9)
) +
  scale_fill_colorblind() +
  scale_color_colorblind() +
  labs(title = "Machine Learning Project")

ggpairs(
  data = df_ROSE,
  columns = c(1:9,11:14),
  mapping = aes(col = churn, alpha = .9)
) +
  scale_fill_colorblind() +
  scale_color_colorblind() +
  labs(title = "Machine Learning Project")


```

## Scale

```{r standardize}

df <- df %>% mutate_if(~!is.factor(.), ~(scale(.) %>% as.vector))
df_ROSE <- df_ROSE %>% mutate_if(~!is.factor(.), ~(scale(.) %>% as.vector))
df_OVER <- df_OVER %>% mutate_if(~!is.factor(.), ~(scale(.) %>% as.vector))
df_UNDER <- df_UNDER %>% mutate_if(~!is.factor(.), ~(scale(.) %>% as.vector))

```


# Predicting Models

##  Logistic Regression

```{r predict}

mod <- glm(churn ~., data = df_UNDER, family = binomial(link='logit'))
summary(mod)

churn_predicted <- factor(ifelse(predict(mod, df[,-c(10)], type = 'response') < 0.5, 'no', 'yes'))

library(caret)

LR_Confusion_Matrix_training <- confusionMatrix(data=churn_predicted, reference = df$churn, positive = 'yes')

CM_Function(LR_Confusion_Matrix_training)

```

Log regression doesn't work. Changing the decision boundary also doesn't help. --> maybe we actually need to resample

https://www.r-bloggers.com/2021/05/class-imbalance-handling-imbalanced-data-in-r/
https://www.analyticsvidhya.com/blog/2016/03/practical-guide-deal-imbalanced-classification-problems/
https://datascientistdiary.com/index.php/2021/09/02/how-to-handle-imbalanced-data-example-in-r/
https://cran.r-project.org/web/packages/imbalance/vignettes/imbalance.pdf


## LDA 

```{r LDA}

# LDA Model Fit on Training
LDA_training <- lda(churn~., df_UNDER)
LDA_training

# Density Plot for Overlapping 
p <- predict(LDA_training, df)
ldahist(data = p$x[,1], g = df$churn, col = "#0D8387")

```

### Confusion Matrix (Training VS Test)

```{r}

# Training 60%
LDA_predictions_training <- predict(LDA_training, df)$class

LDA_Confusion_Matrix_training <- confusionMatrix(data = LDA_predictions_training, reference = df$churn, positive='yes')

CM_Function(LDA_Confusion_Matrix_training)

```

## Random Forest 

Best with ROSE sampling

```{r}
library(randomForest)
library(caret)
set.seed(1)

# Set up cross-validation
control <- trainControl(method = "cv", number = 5, savePredictions = "final", classProbs = TRUE)

# Train the Random Forest model using cross-validation
model_cv <- train(churn ~ ., data = df_ROSE, method = "rf", trControl = control, ntree = 500, importance = TRUE)

# Model performance (average metrics across folds)
model_cv$results

# Confusion Matrix and performance metrics (based on all the cross-validated predictions)
confusionMatrix(model_cv$pred$pred, model_cv$pred$obs, positive = 'yes')
CM_Function(confusionMatrix(model_cv$pred$pred, model_cv$pred$obs, positive = 'yes'))

# Fit the Random Forest model with the optimal mtry value
RF_optimal <- randomForest(churn ~ ., data = df_ROSE, mtry = 6, ntree = 500)

# Mean Decrease Gini
importance <- importance(RF_optimal)
importance


```


## Random Forest V2

```{r}

# ROSE DATA

rf <- randomForest(churn~., data=df_UNDER, proximity=TRUE)

Predictions_OVER <- predict(rf, df_UNDER[,-10])

CM_OVER <- confusionMatrix(Predictions_OVER, df_UNDER$churn, positive = 'yes')

CM_Function(CM_OVER)

# ORIGINAL DATA

Predictions_DATA <- predict(rf, df[,-10])

CM_DATA <- confusionMatrix(Predictions_DATA, df$churn, positive = 'yes')

CM_Function(CM_DATA)

```


## Decision Trees

```{r}

tree <- rpart(churn ~., data = df)

rpart.plot(tree)

printcp(tree)
plotcp(tree)

Predictions_DT <- predict(tree, df[,-10])[,2]

Predictions_DT <- ifelse(Predictions_DT > 0.5, "yes","no")

Predictions_DT <- as.factor(Predictions_DT)

CM_DATA <- confusionMatrix(Predictions_DT, df$churn, positive = 'yes')

CM_Function(CM_DATA)

```

## Neural Net

```{r neural}

library(caret)

nn1 <- train(churn ~ ., data = df_UNDER, method = "nnet")

nn1.pre <- predict(nn1, df[,-c(10)])

confusionMatrix(nn1.pre, df$churn, positive = 'yes')
CM_Function(confusionMatrix(nn1.pre, df$churn, positive = 'yes'))

```


## Support Vector Machines

```{r}

library(e1071)

classifierR = svm(formula = churn ~ .,
                 data = df_UNDER,
                 type = 'C-classification', # this is because we want to make a regression classification
                 kernel = 'radial')

svm_1 <- predict(classifierR, df[,-c(10)])

confusionMatrix(svm_1, df$churn, positive = 'yes')

CM_Function(confusionMatrix(svm_1, df$churn, positive = 'yes'))

```