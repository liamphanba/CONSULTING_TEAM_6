---
title: "CASE_3"
author: "Liam Phan, Michael Bigler, Tania Loureiro, William Elkiess, Dakota Cuellar and Ilyana El Mendili"
date: "`r Sys.Date()`"
output: 
  rmdformats::downcute:
    code_folding: hide
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE,comment = FALSE, error = FALSE,options(scipen=999))
rm(list = ls())
```

# Packages

```{r}
library(DT)
library(adabag)
library(rpart.plot)
library(pROC)
library(summarytools)
library(corrplot)
library(dplyr)
library(GGally)
library(fastDummies)
library(ggcorrplot)
library(klaR)
library(psych)
library(MASS)
library(devtools)
library(ggplot2)
library(ggthemes)
library(GGally)
library(caret)
library(splitTools)
library(rpart)
library(xgboost)
library(caTools)
library(dplyr)
library(caret)
library(naniar)
library(kableExtra)

CM_Function <- function(cm) {

  layout(matrix(c(1,1,2)))
  par(mar=c(2,2,2,2))
  plot(c(100, 345), c(300, 450), type = "n", xlab="", ylab="", xaxt='n', yaxt='n')
  title('CONFUSION MATRIX', cex.main=2)

  # create the matrix 
  rect(150, 430, 240, 370, col='#2F4F4E')
  text(195, 435, 'No', cex=1.2)
  rect(250, 430, 340, 370, col='#0D8387')
  text(295, 435, 'Yes', cex=1.2)
  text(125, 370, 'Predicted', cex=1.3, srt=90, font=2)
  text(245, 450, 'Actual', cex=1.3, font=2)
  rect(150, 305, 240, 365, col='#0D8387')
  rect(250, 305, 340, 365, col='#2F4F4E')
  text(140, 400, 'No', cex=1.2, srt=90)
  text(140, 335, 'Yes', cex=1.2, srt=90)

  # add in the cm results 
  res <- as.numeric(cm$table)
  text(195, 400, res[1], cex=1.6, font=2, col='white')
  text(195, 335, res[2], cex=1.6, font=2, col='white')
  text(295, 400, res[3], cex=1.6, font=2, col='white')
  text(295, 335, res[4], cex=1.6, font=2, col='white')

  # add in the specifics 
  plot(c(100, 0), c(100, 0), type = "n", xlab="", ylab="", main = "DETAILS", xaxt='n', yaxt='n')
  text(10, 85, names(cm$byClass[1]), cex=1.2, font=2)
  text(10, 70, round(as.numeric(cm$byClass[1]), 3), cex=1.2)
  text(30, 85, names(cm$byClass[2]), cex=1.2, font=2)
  text(30, 70, round(as.numeric(cm$byClass[2]), 3), cex=1.2)
  text(50, 85, names(cm$byClass[5]), cex=1.2, font=2)
  text(50, 70, round(as.numeric(cm$byClass[5]), 3), cex=1.2)
  text(70, 85, names(cm$byClass[6]), cex=1.2, font=2)
  text(70, 70, round(as.numeric(cm$byClass[6]), 3), cex=1.2)
  text(90, 85, names(cm$byClass[7]), cex=1.2, font=2)
  text(90, 70, round(as.numeric(cm$byClass[7]), 3), cex=1.2)

  # add in the accuracy information 
  text(30, 35, names(cm$overall[1]), cex=1.5, font=2)
  text(30, 20, round(as.numeric(cm$overall[1]), 3), cex=1.4)
  text(70, 35, names(cm$overall[2]), cex=1.5, font=2)
  text(70, 20, round(as.numeric(cm$overall[2]), 3), cex=1.4)
}  


```

# DATA AND QUICK FACTORING

```{r}

df <- readxl::read_xls('Cchurn.xls')
df$international_plan <- factor(df$international_plan, levels = c('no', 'yes'), labels = c('0','1'))
df$voice_mail_plan <- factor(df$voice_mail_plan, levels = c('no', 'yes'), labels = c('0','1'))
df$churn <- factor(df$churn, levels = c('no', 'yes'), labels = c('0','1'))

```

## SUMMARY

```{r}
print(summarytools::dfSummary(df), method = 'render')
```

* We have no missing values -> perfect
* Heavily uneven counts of dependent variable (86 % no / 14 % yes) -> maybe sample for equality / maybe not because we loose information of other data
* Independent variables are on different scales -> standardize
* two (maybe three) categorical predictors: International plan / voice_mail_plan (/ maybe number_customer_service_calls) -> dummy encode -> not necessary as already 0 and 1
* Rest of data is numeric and most of the variables looks normally distributed with exception of number_vmail_messages and totat_intl_calls
  * transform these value to make them normal?
  * maybe make parts of them categorical? (recieving voice mail or not, calling internationally or not)
  * or maybe the categorical values that we have already give an indication for this
  * Test normality of variables
* Can variables be combined? We have day / eve / night / intl calls and for each of them minutes / calls / charge. Maybe we can combine this into one metric. Maybe average cost per minute or average cost per call? 

## CORRELATION PLOT BEFORE DATA ENGINEERING

```{r correlation}

df_numeric <- select_if(df, is.numeric)  # Subset numeric columns with dplyr

M <- cor(df_numeric)

p.mat <- cor_pmat(df_numeric)

ggcorrplot(M, hc.order = TRUE, type = "lower", lab = TRUE, p.mat = p.mat, sig.level=0.05, lab_size = 2, tl.cex = 10,outline.col = "white", ggtheme = ggplot2::theme_minimal(), colors = c("#2F4F4E", "white", "#0D8387")) 

```

Proves theory from before -> we can make one metric out of charge and minutes --> charge / minutes

## DATA ENGINEERING

```{r}
df$total_day_charge_per_minute <- ifelse(df$total_day_minutes == 0, 0, df$total_day_charge / df$total_day_minutes)
df$total_eve_charge_per_minute <- ifelse(df$total_eve_minutes == 0, 0, df$total_eve_charge / df$total_eve_minutes)
df$total_night_charge_per_minute <- ifelse(df$total_night_minutes == 0, 0, df$total_night_charge / df$total_night_minutes)
df$total_intl_charge_per_minute <- ifelse(df$total_intl_minutes == 0, 0, df$total_intl_charge / df$total_intl_minutes)
df <- subset(df, select = -c(total_day_charge, total_day_minutes, total_eve_charge, total_eve_minutes, total_night_charge, total_night_minutes, total_intl_charge, total_intl_minutes))
```

## CORRELATION PLOT AFTER DATA ENGINEERING

```{r}

df_numeric <- select_if(df, is.numeric)  # Subset numeric columns with dplyr

M <- cor(df_numeric)

p.mat <- cor_pmat(df_numeric)

ggcorrplot(M, hc.order = TRUE, type = "lower", lab = TRUE, p.mat = p.mat, sig.level=0.05, lab_size = 2, tl.cex = 10,outline.col = "white", ggtheme = ggplot2::theme_minimal(), colors = c("#2F4F4E", "white", "#0D8387")) 

```

Now we have non-correlated data

## HIGHER ORDER FEATURES

Only squaring as we have no negative data. Cubing would be needed with negative data. 

```{r}

# squared
df2 <- df^2
df2 <- df2[,-c(2,3,10)]
colnames(df2) <- paste0(colnames(df2), '_sqd')

df <- cbind(df,df2)

```

## Relationship between data in higher order

```{r}
# theme_set(theme_minimal())
# 
# ggpairs(
#   data = df,
#   columns = c(1:9, 11:25),
#   mapping = aes(col = churn, alpha = .9)
# ) +
#   scale_fill_colorblind() +
#   scale_color_colorblind()
```

## SAMPLING METHODS

As we have unbalanced data we need to use a sampling method to balance the classes. Hereby there are four different methods. OVER / UNDER / BOTH / ROSE. 

```{r}

library(ROSE)

# OVER
df_OVER <- ovun.sample(churn~., data = df, method = "over")$data

table(df$churn)
table(df_OVER$churn)

# UNDER
df_UNDER <- ovun.sample(churn~., data = df, method = "under")$data

table(df$churn)
table(df_UNDER$churn)

# BOTH
df_BOTH <- ovun.sample(churn~., data = df, method = "both")$data

table(df$churn)
table(df_BOTH$churn)

# ROSE
df_ROSE <- ROSE(churn ~ ., data = df, seed = 1, p = 0.5)$data

```

## SAMPLING POST VISUALIZATION

```{r}

# theme_set(theme_minimal())
# 
# ggpairs(
#   data = df_ROSE,
#   columns = c(1:9, 11:25),
#   mapping = aes(col = churn, alpha = .9)
# ) +
#   scale_fill_colorblind() +
#   scale_color_colorblind() +
#   labs(title = "Machine Learning Project")
# 
# ggpairs(
#   data = df_OVER,
#   columns = c(1:9, 11:25),
#   mapping = aes(col = churn, alpha = .9)
# ) +
#   scale_fill_colorblind() +
#   scale_color_colorblind() +
#   labs(title = "Machine Learning Project")

# ggpairs(
#   data = df_UNDER,
#   columns = c(1:9, 11:25),
#   mapping = aes(col = churn, alpha = .9)
# ) +
#   scale_fill_colorblind() +
#   scale_color_colorblind() +
#   labs(title = "Machine Learning Project")

# ggpairs(
#   data = df_BOTH,
#   columns = c(1:9, 11:25),
#   mapping = aes(col = churn, alpha = .9)
# ) +
#   scale_fill_colorblind() +
#   scale_color_colorblind() +
#   labs(title = "Machine Learning Project")
```

## TRAIN AND TEST SPLIT

As we need to test the models we need to split the sampled data. 

```{r}
set.seed(1)
data <- df_OVER # choose which data to use df_ROSE / df_BOTH / df_UNDER / df_OVER / df
inds <- splitTools::partition(data$churn, p = c(train = 0.7, test = 0.3))
dftrain <- data[inds$train,]
dftest <- data[inds$test,]
```

## SCALING 

As some methods need scaled data we scale the data here to be centered. 

```{r}
norm.value <- preProcess(dftrain, method = c("center", "scale"))
dftrain <- predict(norm.value, dftrain)
dftest <- predict(norm.value, dftest)

df_original_test <- predict(norm.value, df)

```

# PREDICTIVE MODELS

## BOOSTING

```{r}

set.seed(123)

# train bagged model
mod.boost <- boosting(churn ~., data=dftrain)

predicted.boost <- factor(predict(mod.boost, dftest, type="class")$class)

PRED_BOOSTING <- predicted.boost

confmat.boost <- confusionMatrix(data=predicted.boost, reference = dftest$churn, positive = '1')

CM_Function(confmat.boost)

roc_score.boost =roc(factor(dftest$churn, ordered=TRUE), factor(predicted.boost, ordered=TRUE))
plot(roc_score.boost ,main ="ROC curve")

```

## BOOSTING ON ORIGINAL DATA

```{r}

predicted.boost <- factor(predict(mod.boost, df_original_test, type="class")$class)

PRED_BOOSTING_ORIGINAL <- predicted.boost

confmat.boost <- confusionMatrix(data=predicted.boost, reference = df_original_test$churn, positive = '1')

CM_Function(confmat.boost)

roc_score.boost =roc(factor(df_original_test$churn, ordered=TRUE), factor(predicted.boost, ordered=TRUE))
plot(roc_score.boost ,main ="ROC curve")


```

## CTREE

```{r}

set.seed(123)

tree_full <- rpart(churn ~ ., 
              data = dftrain, 
              method = "class",  # "class" because Y is a binary factor
              minbucket = 1,
              cp = 0.00001) 

# Plot tree
rpart.plot(tree_full, yesno = TRUE, digits =-6)

min_xerr<- which.min(tree_full$cptable[,"xerror"]) # select minimum cross-validation error
cp_bp <- tree_full$cptable[min_xerr,"CP"]  # find the corresponding CP value, to get the "best pruned " tree


mod.pruned_tree<- prune(tree_full, cp = cp_bp) # re-compute the tree with the selected Cp
rpart.plot(mod.pruned_tree, yesno = TRUE, digits =-3)

predicted.pruned_tree <- predict(mod.pruned_tree, dftest[,-c(10)], type = "class")

PRED_CTREE <- predicted.pruned_tree

confmat.prunned_tree <- confusionMatrix(data=predicted.pruned_tree, reference = dftest$churn, positive = '1')

CM_Function(confmat.prunned_tree)

roc_score.prunned_tree =roc(factor(dftest$churn, ordered=TRUE), factor(predicted.pruned_tree, ordered=TRUE))
plot(roc_score.prunned_tree ,main ="ROC curve")

```

## CTREE ON ORIGINAL DATA

```{r}

predicted.pruned_tree <- predict(mod.pruned_tree, df_original_test[,-c(10)], type = "class")

PRED_CTREE_ORIGINAL <- predicted.pruned_tree

confmat.prunned_tree <- confusionMatrix(data=predicted.pruned_tree, reference = df_original_test$churn, positive = '1')

CM_Function(confmat.prunned_tree)

roc_score.prunned_tree =roc(factor(df_original_test$churn, ordered=TRUE), factor(predicted.pruned_tree, ordered=TRUE))
plot(roc_score.prunned_tree ,main ="ROC curve")


```

## VARIABLES IMPORTANCES

```{r}

relevance<-as.data.frame(mod.pruned_tree$variable.importance) #we get the ranking of the variables by importance
kable(relevance, row.names = T,col.names="Variable Importance") %>% kable_paper("hover", full_width = T) #built table

relevance

```

## BAGGING

```{r}

set.seed(123)
library(ipred)
library(pROC)

# train bagged model
ames_bag1 <- bagging(
  formula = churn ~ .,
  data = dftrain, 
  nbagg = 100,  
  coob = TRUE,
  control = rpart.control(minsplit = 2, cp = 0)
  )

ames_bag1

predicted <- factor(ifelse(predict(ames_bag1, dftest[,-c(10)], type = 'prob')[,2] >= 0.5, 1, 0))

PRED_BAGGING <- predicted
                    
CM_Function(confusionMatrix(data=predicted, reference = dftest$churn, positive = '1'))

roc_score=roc(factor(dftest$churn, ordered=TRUE), factor(predicted, ordered=TRUE)) #AUC score

auc <- round(auc(factor(dftest$churn, ordered=TRUE), factor(predicted, ordered=TRUE)),4)

ggroc(roc_score, colour = '#0D8387', size = 1) +
 ggtitle(paste0('ROC Curve ', '(AUC = ', auc, ')')) + theme_minimal() + theme(plot.title = element_text(face = "bold")) + labs(x="Specificity", y="Sensitivity")

```


## BAGGING ON ORIGINAL DATA

```{r}

predicted <- factor(ifelse(predict(ames_bag1, df_original_test[,-c(10)], type = 'prob')[,2] >= 0.5, 1, 0))

PRED_BAGGING_ORIGINAL <- predicted
                    
CM_Function(confusionMatrix(data=predicted, reference = df_original_test$churn, positive = '1'))

roc_score=roc(factor(df_original_test$churn, ordered=TRUE), factor(predicted, ordered=TRUE)) #AUC score

auc <- round(auc(factor(df_original_test$churn, ordered=TRUE), factor(predicted, ordered=TRUE)),4)

ggroc(roc_score, colour = '#0D8387', size = 1) +
 ggtitle(paste0('ROC Curve ', '(AUC = ', auc, ')')) + theme_minimal() + theme(plot.title = element_text(face = "bold")) + labs(x="Specificity", y="Sensitivity")


```


## KNN

```{r}

set.seed(1)

df <- data.frame(k = seq(1, 30, 1), accuracy = rep(0, 30), sensitivity = rep(0, 30))

# iterating over different ks
for(i in 1:30){
  # nearest neighbor
  KNN1 <- knn3(y = dftrain$churn, x = dftrain[,-c(10)], k = i)

  # predictions response 
  KNN1.pred.valid.resp <- predict(KNN1, dftest[,-c(10)], type = "class")
  
  # predictions prob 
  KNN1.pred.valid.prob <- predict(KNN1, dftest[,-c(10)], type = "prob")[,2]
  
  # Confusionmatrix
  df$sensitivity[i] <- confusionMatrix(KNN1.pred.valid.resp, dftest$churn, positive = "1")$byClass[1]
  df$accuracy[i] <- confusionMatrix(KNN1.pred.valid.resp, dftest$churn, positive = "1")$overall[1]

}

# plot the k's
ggplot(df, aes(x=k)) + 
  geom_line(aes(y = sensitivity, colour = "Sensitivity")) + 
  geom_line(aes(y = accuracy, colour = "Accuracy")) + 
  labs(x = "Number of k nearest neighbours", 
       y = "Accuracy / Sensitivity", title = "Accuracy / Sensitivity regarding k") +
  theme_minimal() + 
  scale_y_continuous(name = "Sensitivity / Accuracy", limits = c(0.7, 1)) +
    scale_color_manual(name = "Values", values = c("Sensitivity" = "darkblue", "Accuracy" = "red")) + 
  xlim (1, 30)


mod.knn <- knn3(y = dftrain$churn, x = dftrain[,-c(10)], k = 2)

predicted.knn <- predict(mod.knn, dftest[,-c(10)], type = "class")

PRED_KNN <- predicted.knn

confmat.knn <- confusionMatrix(data=predicted.knn, reference = dftest$churn, positive = '1')

CM_Function(confmat.knn)

roc_score.qda =roc(factor(dftest$churn, ordered=TRUE), factor(predicted.knn, ordered=TRUE))
plot(roc_score.qda ,main ="ROC curve")


```

## KNN ON ORIGINAL DATA

```{r}

predicted.knn <- predict(mod.knn, df_original_test[,-c(10)], type = "class")

PRED_KNN_ORIGINAL <- predicted.knn

confmat.knn <- confusionMatrix(data=predicted.knn, reference = df_original_test$churn, positive = '1')

CM_Function(confmat.knn)

roc_score.qda =roc(factor(df_original_test$churn, ordered=TRUE), factor(predicted.knn, ordered=TRUE))
plot(roc_score.qda ,main ="ROC curve")


```

## QDA

```{r}

mod.qda <- qda(churn ~., data = dftrain)

predicted.qda <- predict(mod.qda, dftest[,-c(10)])$class

confmat.qda <- confusionMatrix(data=predicted.qda, reference = dftest$churn, positive = '1')

CM_Function(confmat.qda)

roc_score.qda =roc(factor(dftest$churn, ordered=TRUE), factor(predicted.qda, ordered=TRUE))
plot(roc_score.qda ,main ="ROC curve")

```

## QDA ON ORIGINAL DATA 

```{r}

predicted.qda <- predict(mod.qda, df_original_test[,-c(10)])$class

confmat.qda <- confusionMatrix(data=predicted.qda, reference = df_original_test$churn, positive = '1')

CM_Function(confmat.qda)

roc_score.qda =roc(factor(df_original_test$churn, ordered=TRUE), factor(predicted.qda, ordered=TRUE))
plot(roc_score.qda ,main ="ROC curve")


```

## QLOG

```{r qda}

mod.log <- glm(churn ~., data = dftrain, family = binomial(link = "probit"))

s <- step(mod.log)

mod.log <- glm(s$formula, data = dftrain, family = binomial(link = "probit"))

predicted.log <- factor(ifelse(predict(mod.log, dftest[,-c(10)], type='response')>0.5,1,0))

confmat.log <- confusionMatrix(data=predicted.log, reference = dftest$churn, positive = '1')

CM_Function(confmat.log)

roc_score.log =roc(factor(dftest$churn, ordered=TRUE), factor(predicted.log, ordered=TRUE))
plot(roc_score.log ,main ="ROC curve")

```

## GAUSSIAN SVM

```{r}
library(e1071)
mod.svm  = svm(formula = churn ~ .,
               data = dftrain,
                 type = 'C-classification', # this is because we want to make a regression classification
                 kernel = 'radial')

predicted.svm <- predict(mod.svm, dftest[,-c(10)])

confmat.svm <- confusionMatrix(data=predicted.svm, reference = dftest$churn, positive = '1')

CM_Function(confmat.svm)

roc_score.svm =roc(factor(dftest$churn, ordered=TRUE), factor(predicted.svm, ordered=TRUE))
plot(roc_score.svm ,main ="ROC curve")
```


# ENSEMBLES - MAJORITY VOTING

**BOOSTING** **CTREE** **BAGGING**

```{r}


ENSEMBLES <- cbind(PRED_BOOSTING,PRED_CTREE,PRED_BAGGING)
ENSEMBLES <- as.data.frame(ENSEMBLES)
ENSEMBLES <- ifelse(ENSEMBLES == 2, 1, 0)
MAJORITY_VOTE <- rep(0,nrow(ENSEMBLES))


MAJORITY_VOTE <- ifelse(rowSums(ENSEMBLES) > (ncol(ENSEMBLES)-1)/2, 1, 0)

ENSEMBLES <- cbind(ENSEMBLES,MAJORITY_VOTE)
ENSEMBLES <- as.data.frame(ENSEMBLES)
ENSEMBLES$MAJORITY_VOTE <- as.factor(ENSEMBLES$MAJORITY_VOTE)

CM_ENSEMBLES <- confusionMatrix(data=ENSEMBLES$MAJORITY_VOTE, reference = dftest$churn, positive = '1')

CM_Function(CM_ENSEMBLES)

roc_score =roc(factor(dftest$churn, ordered=TRUE), factor(ENSEMBLES$MAJORITY_VOTE, ordered=TRUE))

auc <- round(auc(factor(dftest$churn, ordered=TRUE), factor(ENSEMBLES$MAJORITY_VOTE, ordered=TRUE)),4)

ggroc(roc_score, colour = '#0D8387', size = 1) +
 ggtitle(paste0('ROC Curve ', '(AUC = ', auc, ')')) + theme_minimal() + theme(plot.title = element_text(face = "bold")) + labs(x="Specificity", y="Sensitivity")


```

## ENSEMBLES - MAJORITY VOTING ON ORIGINAL

**BOOSTING** **CTREE** **BAGGING**

```{r}


ENSEMBLES <- cbind(PRED_BOOSTING_ORIGINAL,PRED_CTREE_ORIGINAL,PRED_BAGGING_ORIGINAL)
ENSEMBLES <- as.data.frame(ENSEMBLES)
ENSEMBLES <- ifelse(ENSEMBLES == 2, 1, 0)
MAJORITY_VOTE <- rep(0,nrow(ENSEMBLES))


MAJORITY_VOTE <- ifelse(rowSums(ENSEMBLES) > (ncol(ENSEMBLES)-1)/2, 1, 0)

ENSEMBLES <- cbind(ENSEMBLES,MAJORITY_VOTE)
ENSEMBLES <- as.data.frame(ENSEMBLES)
ENSEMBLES$MAJORITY_VOTE <- as.factor(ENSEMBLES$MAJORITY_VOTE)

CM_ENSEMBLES <- confusionMatrix(data=ENSEMBLES$MAJORITY_VOTE, reference = df_original_test$churn, positive = '1')

CM_Function(CM_ENSEMBLES)

roc_score =roc(factor(df_original_test$churn, ordered=TRUE), factor(ENSEMBLES$MAJORITY_VOTE, ordered=TRUE))

auc <- round(auc(factor(df_original_test$churn, ordered=TRUE), factor(ENSEMBLES$MAJORITY_VOTE, ordered=TRUE)),4)

ggroc(roc_score, colour = '#0D8387', size = 1) +
 ggtitle(paste0('ROC Curve ', '(AUC = ', auc, ')')) + theme_minimal() + theme(plot.title = element_text(face = "bold")) + labs(x="Specificity", y="Sensitivity")


```

# ENSEMBLES - MAJORITY VOTING

**KNN** **CTREE** **BAGGING**

```{r}


ENSEMBLES <- cbind(PRED_KNN,PRED_CTREE,PRED_BAGGING)
ENSEMBLES <- as.data.frame(ENSEMBLES)
ENSEMBLES <- ifelse(ENSEMBLES == 2, 1, 0)
MAJORITY_VOTE <- rep(0,nrow(ENSEMBLES))


MAJORITY_VOTE <- ifelse(rowSums(ENSEMBLES) > (ncol(ENSEMBLES)-1)/2, 1, 0)

ENSEMBLES <- cbind(ENSEMBLES,MAJORITY_VOTE)
ENSEMBLES <- as.data.frame(ENSEMBLES)
ENSEMBLES$MAJORITY_VOTE <- as.factor(ENSEMBLES$MAJORITY_VOTE)

CM_ENSEMBLES <- confusionMatrix(data=ENSEMBLES$MAJORITY_VOTE, reference = dftest$churn, positive = '1')

CM_Function(CM_ENSEMBLES)

roc_score =roc(factor(dftest$churn, ordered=TRUE), factor(ENSEMBLES$MAJORITY_VOTE, ordered=TRUE))

auc <- round(auc(factor(dftest$churn, ordered=TRUE), factor(ENSEMBLES$MAJORITY_VOTE, ordered=TRUE)),4)

ggroc(roc_score, colour = '#0D8387', size = 1) +
 ggtitle(paste0('ROC Curve ', '(AUC = ', auc, ')')) + theme_minimal() + theme(plot.title = element_text(face = "bold")) + labs(x="Specificity", y="Sensitivity")


```

## ENSEMBLES - MAJORITY VOTING ON ORIGINAL

**KNN** **CTREE** **BAGGING**

```{r}


ENSEMBLES <- cbind(PRED_KNN_ORIGINAL,PRED_CTREE_ORIGINAL,PRED_BAGGING_ORIGINAL)
ENSEMBLES <- as.data.frame(ENSEMBLES)
ENSEMBLES <- ifelse(ENSEMBLES == 2, 1, 0)
MAJORITY_VOTE <- rep(0,nrow(ENSEMBLES))


MAJORITY_VOTE <- ifelse(rowSums(ENSEMBLES) > (ncol(ENSEMBLES)-1)/2, 1, 0)

ENSEMBLES <- cbind(ENSEMBLES,MAJORITY_VOTE)
ENSEMBLES <- as.data.frame(ENSEMBLES)
ENSEMBLES$MAJORITY_VOTE <- as.factor(ENSEMBLES$MAJORITY_VOTE)

CM_ENSEMBLES <- confusionMatrix(data=ENSEMBLES$MAJORITY_VOTE, reference = df_original_test$churn, positive = '1')

CM_Function(CM_ENSEMBLES)

roc_score =roc(factor(df_original_test$churn, ordered=TRUE), factor(ENSEMBLES$MAJORITY_VOTE, ordered=TRUE))

auc <- round(auc(factor(df_original_test$churn, ordered=TRUE), factor(ENSEMBLES$MAJORITY_VOTE, ordered=TRUE)),4)

ggroc(roc_score, colour = '#0D8387', size = 1) +
 ggtitle(paste0('ROC Curve ', '(AUC = ', auc, ')')) + theme_minimal() + theme(plot.title = element_text(face = "bold")) + labs(x="Specificity", y="Sensitivity")


```



# PRESENTATION ASSETS

```{r}

rm(list = ls())

```

```{r}

# READ DATA
df <- readxl::read_xls('Cchurn.xls')
df$international_plan <- factor(df$international_plan, levels = c('no', 'yes'), labels = c('0','1'))
df$voice_mail_plan <- factor(df$voice_mail_plan, levels = c('no', 'yes'), labels = c('0','1'))
df$churn <- factor(df$churn, levels = c('no', 'yes'), labels = c('No','Yes'))

# DATA ENGINEERING
df$total_day_charge_per_minute <- ifelse(df$total_day_minutes == 0, 0, df$total_day_charge / df$total_day_minutes)
df$total_eve_charge_per_minute <- ifelse(df$total_eve_minutes == 0, 0, df$total_eve_charge / df$total_eve_minutes)
df$total_night_charge_per_minute <- ifelse(df$total_night_minutes == 0, 0, df$total_night_charge / df$total_night_minutes)
df$total_intl_charge_per_minute <- ifelse(df$total_intl_minutes == 0, 0, df$total_intl_charge / df$total_intl_minutes)
df <- subset(df, select = -c(total_day_charge, total_day_minutes, total_eve_charge, total_eve_minutes, total_night_charge, total_night_minutes, total_intl_charge, total_intl_minutes))

colnames(df) <- c("Account Length", "International Plan","Voice Mail Plan","Voice Mail Messages","Total Days Calls","Total Evening Calls","Total Night Calls","Total Internation Calls","Total Customer Service Call","Customer Churn","Total Day Charge/Minute", "Total Evening Charge/Minute","Total Night Charge/Minute","Total International Charge/Minute")

``` 

## PAIRS PLOT

```{r, fig.height=12,fig.width=12}

# Load the necessary libraries
library(ggplot2)
library(GGally)
library(ggthemes)

# Set the main color palette
colors <- c("#0D8387", "#870D27")

# Create the ggpair plot 
PAIRS1 <- ggpairs(df,columns = c(1:4), mapping = aes(col = `Customer Churn`, alpha = 0.9)) + scale_color_manual(values = colors) + scale_fill_manual(values = colors) + labs(title = "Customer Telecommunication Data", subtitle = "Customer Churn = Yes  is red", caption="From Variable 1 to 4") + theme(plot.title = element_text(face = "bold")) 

PAIRS1

PAIRS2 <- ggpairs(df,columns = c(5:9), mapping = aes(col = `Customer Churn`, alpha = 0.9)) + scale_color_manual(values = colors) + scale_fill_manual(values = colors) + labs(title = "Customer Telecommunication Data", subtitle = "Customer Churn = Yes  is red", caption="From Variable 5 to 9") + theme(plot.title = element_text(face = "bold"))

PAIRS2

PAIRS3 <- ggpairs(df,columns = c(10:10), mapping = aes(col = `Customer Churn`, alpha = 0.9)) + scale_color_manual(values = colors) + scale_fill_manual(values = colors) + labs(title = "Customer Telecommunication Data", subtitle = "", y="Count") + theme(plot.title = element_text(face = "bold")) + theme_minimal() + theme(plot.title = element_text(face = "bold")) + annotate("text", x = 2, y = 900, label = "14.14%", colour = "#870D27", size=8) + annotate("text", x = 1, y = 4500, label = "85.86%", colour = "#0D8387", size=8) + theme(axis.text.x=element_text(size=16))

PAIRS3

PAIRS4 <- ggpairs(df,columns = c(11:14), mapping = aes(col = `Customer Churn`, alpha = 0.9)) + scale_color_manual(values = colors) + scale_fill_manual(values = colors) + labs(title = "Customer Telecommunication Data", subtitle = "Customer Churn = Yes  is red",caption="From Variable 11 to 14") + theme(plot.title = element_text(face = "bold"))

PAIRS4

df$`Customer Churn` <- factor(df$`Customer Churn`, levels = c('No', 'Yes'), labels = c(0,1))

df$`Customer Churn` <- as.integer(df$`Customer Churn`)

df$`Customer Churn` <- df$`Customer Churn` -1 

Proportions_Churn <- sum(df$`Customer Churn`[df$`Customer Churn` == 1])/nrow(df)
Proportions_No_Churn <- 1-Proportions_Churn

```

Proportions of Customer who churned => 14.14% Versus 85.86% who didn't churn. 



